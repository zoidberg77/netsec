{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder# instantiate labelencoder object\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV# Create the parameter grid based on the results of random search \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "data_path = './malicious-connection-dataset';\n",
    "train_bad_data_path = './malicious-connection-dataset/df_bad.csv';\n",
    "train_good_data_path = './malicious-connection-dataset/df_good.csv';\n",
    "classify_data_path = './malicious-connection-dataset/df_good.csv';\n",
    "\n",
    "class SimpleLoader:\n",
    "    \n",
    "    def __init__ (self, is_training_session = True):\n",
    "        self._is_training_session = is_training_session\n",
    "    \n",
    "    def load(self, data_path = '',\n",
    "                train_bad_data_path = '',\n",
    "                train_good_data_path = '',\n",
    "                classify_data_path = ''):\n",
    "        \n",
    "        for dirname, _, filenames in os.walk(data_path):\n",
    "            for filename in filenames:\n",
    "                os.path.join(dirname, filename)\n",
    "                \n",
    "        df = None\n",
    "        if(self._is_training_session):\n",
    "            df_bad = pd.read_csv(train_bad_data_path, encoding='ISO-8859-2')\n",
    "            df_bad.rename(columns={'Unnamed: 0':'unnamed'}, inplace=True)\n",
    "            df_bad.drop('unnamed', axis=1, inplace=True)\n",
    "            df_bad.insert(0, 'label', 0)\n",
    "\n",
    "            df_good = pd.read_csv(train_good_data_path, encoding='ISO-8859-2')  \n",
    "            df_good.rename(columns={'Unnamed: 0':'unnamed'}, inplace=True)\n",
    "            df_good.drop('unnamed', axis=1, inplace=True)\n",
    "            df_good.insert(0, 'label', 1)\n",
    "            df = pd.concat([df_good, df_bad], ignore_index=True)\n",
    "        else:\n",
    "            df = pd.read_csv(classify_data_path, encoding='ISO-8859-2')\n",
    "            df.rename(columns={'Unnamed: 0':'unnamed'}, inplace=True)\n",
    "            df.drop('unnamed', axis=1, inplace=True)\n",
    "        return df\n",
    "\n",
    "    \n",
    "#train_loader = SimpleLoader(True)\n",
    "#df = train_loader.load(data_path=data_path, \n",
    "#                  train_bad_data_path=train_bad_data_path, \n",
    "#                  train_good_data_path = train_good_data_path)\n",
    "\n",
    "classify_loader = SimpleLoader(False)\n",
    "df_classify = classify_loader.load(data_path=data_path, \n",
    "                                   classify_data_path=classify_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePreProcessor:\n",
    "    def __init__ (self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess_all(self, df):\n",
    "        df = self.convert_time(df)\n",
    "        df = self.convert_numericals(df)\n",
    "        df = self.encode_categorical(df)\n",
    "        df = self.normalize_features(df)\n",
    "        return df\n",
    "        \n",
    "    def encode_categorical(self, df):\n",
    "        cols = ['ip', 'port']\n",
    "        le = LabelEncoder()\n",
    "        df[cols] = df[cols].apply(lambda col: le.fit_transform(col))\n",
    "        return df\n",
    "    \n",
    "    def normalize_features(self, df):\n",
    "        cols = ['times', 'di', 'do', 'pi', 'po', 'ip', 'port']\n",
    "        df[cols] = (df[cols]-df[cols].mean())/df[cols].std()\n",
    "        return df\n",
    "\n",
    "    def convert_time(self, df):\n",
    "        df[['times']] = df[['times']].apply(self._time_converter, axis=0)\n",
    "        return df\n",
    "    \n",
    "    def convert_numericals(self, df):\n",
    "        df[['di']] = df[['di']].apply(self._num_converter, axis=0)\n",
    "        df[['do']] = df[['do']].apply(self._num_converter, axis=0)\n",
    "        df[['pi']] = df[['pi']].apply(self._num_converter, axis=0)\n",
    "        df[['po']] = df[['po']].apply(self._num_converter, axis=0)\n",
    "        return df\n",
    "        \n",
    "    def _num_converter(self, s):\n",
    "        s = s.fillna(0).astype(str).str.split(\",\", expand = False).apply(\n",
    "                lambda x : [int(y) for y in x]\n",
    "            )\n",
    "        s = s.apply(lambda x : np.std(x))\n",
    "        return s\n",
    "        \n",
    "    def _time_converter(self, s):\n",
    "        s = s.fillna(0).astype(str).str.split(\"|\", expand = False).apply(\n",
    "                lambda x : [[int(i) for i in y.split(',')] for y in x]\n",
    "            )\n",
    "        s = s.apply(lambda x : np.std(np.concatenate(x)))\n",
    "        return s\n",
    "\n",
    "#train_processor = SimplePreProcessor(True)\n",
    "#preprocessor = SimplePreProcessor()\n",
    "\n",
    "#df = preprocessor.preprocess_all(df)\n",
    "#df_classify = preprocessor.preprocess_all(df_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b5b257476c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plot corellation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'times'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'di'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'po'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'port'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ax = sns.heatmap(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot corellation\n",
    "cols = ['label', 'times', 'di', 'do', 'pi', 'po', 'ip', 'port']\n",
    "corr = df[cols].corr()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel():\n",
    "    def __init__ (self):\n",
    "        self._feature_selector_model = None\n",
    "        self._classifier_model = None\n",
    "        \n",
    "    def train(self, df):\n",
    "        model, X_train, X_test, X_train, X_test, y_train, y_test = self._selective_train_test_split(df);\n",
    "        self._feature_selector_model = model\n",
    "        param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [2, 20, 40],\n",
    "        'max_features': [1, 3, 7],\n",
    "        'min_samples_leaf': [2, 4, 8],\n",
    "        'min_samples_split': [5, 10, 10],\n",
    "        'n_estimators': [5, 25, 50]\n",
    "        }\n",
    "        rf = RandomForestClassifier()\n",
    "        clf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                                  cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = (clf.predict(X_test))\n",
    "        target_names = ['good', 'bad']\n",
    "        self._classifier_model = clf\n",
    "        \n",
    "        return (classification_report(y_test, y_pred, target_names=target_names),\n",
    "                accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        \n",
    "        \n",
    "    def classify(self, df):\n",
    "        if self._feature_selector_model is None or self._classifier_model is None:\n",
    "            raise('Model appears to be untrained.')\n",
    "            \n",
    "        X = self._feature_selector_model.transform(df[['ip', 'port', 'times', 'di', 'do', 'pi', 'po']])\n",
    "        y_pred = self._classifier_model.predict(X)\n",
    "        return y_pred\n",
    "            \n",
    "        \n",
    "    def _selective_train_test_split(self, df):\n",
    "        #Train Test split\n",
    "        #Feature selection via cheap classifier\n",
    "        X = df[['ip', 'port', 'times', 'di', 'do', 'pi', 'po']]\n",
    "        y = df[['label']]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "        #Feature selection via cheap classifier\n",
    "        clf = ExtraTreesClassifier(n_estimators=50)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "\n",
    "        model = SelectFromModel(clf, prefit=True, threshold='0.5*mean')\n",
    "        X_train = model.transform(X_train)\n",
    "        X_test = model.transform(X_test)\n",
    "        return model, X_train, X_test, X_train, X_test, y_train, y_test\n",
    "\n",
    "#simple_model = SimpleModel()\n",
    "#simple_model.train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-9036254c146a>:52: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 729 out of 729 | elapsed:  5.4min finished\n",
      "/usr/local/anaconda3/envs/netsec/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self._train_loader = SimpleLoader(True)\n",
    "        self._classify_loader = SimpleLoader(False)\n",
    "        self._preprocessor = SimplePreProcessor()\n",
    "        self._simple_model = SimpleModel()\n",
    "\n",
    "    def fit_csv(self, data_path, train_bad_data_path, train_good_data_path):\n",
    "        df = self._train_loader.load(data_path=data_path, \n",
    "                  train_bad_data_path=train_bad_data_path, \n",
    "                  train_good_data_path = train_good_data_path)\n",
    "        df = self._preprocessor.preprocess_all(df)\n",
    "        self._simple_model = SimpleModel()\n",
    "        return self._simple_model.train(df)\n",
    "\n",
    "\n",
    "    def predict_csv(self, data_path, classify_data_path):\n",
    "        df = self._classify_loader.load(classify_data_path=classify_data_path)\n",
    "        df = self._preprocessor.preprocess_all(df)\n",
    "        return self._simple_model.classify(df)\n",
    "\n",
    "    def predict_df(self, df):\n",
    "        df = self._preprocessor.preprocess_all(df)\n",
    "        return self._simple_model.classify(df)\n",
    "\n",
    "data_path = './malicious-connection-dataset';\n",
    "train_bad_data_path = './malicious-connection-dataset/df_bad.csv';\n",
    "train_good_data_path = './malicious-connection-dataset/df_good.csv';\n",
    "classify_data_path = './malicious-connection-dataset/df_good.csv';\n",
    "\n",
    "simple_pipeline = SimplePipeline()\n",
    "report, accuracy, confusion = simple_pipeline.fit_csv(data_path, train_bad_data_path, train_good_data_path)\n",
    "y_pred_csv = simple_pipeline.predict_csv(data_path, classify_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = simple_pipeline.predict_df(df_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'client/model.sav'\n",
    "pickle.dump(simple_pipeline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                    0\n",
      "ip                                              141.8.224.169\\n\n",
      "port                                                     http\\n\n",
      "times         73951142,74099359|74100335,74261630|74262194,7...\n",
      "di            0,268,0,0,0,0,268,0,0,0,0,268,0,0,0,0,0,0,268,...\n",
      "do            0,0,2087,0,0,0,0,0,2091,0,0,0,0,1420,657,0,0,0...\n",
      "pi            1,2,1,0,0,0,2,0,1,0,0,2,0,0,0,0,0,0,2,0,0,1,0,...\n",
      "po            0,2,3,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
      "type                        eb7c74c66f801abde07e0d1a72cbec79(1)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('malicious-connection-dataset/df_bad.csv', encoding='ISO-8859-2')\n",
    "\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
